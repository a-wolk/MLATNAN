{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/piotr/.local/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /home/piotr/.local/lib/python3.10/site-packages (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /home/piotr/.local/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/piotr/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/piotr/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/piotr/.local/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/piotr/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/piotr/.local/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas numpy scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "BASE_DIR = \"narpsdata/extended\"\n",
    "common_cols = [0, 1, 2]\n",
    "\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename, delimiter=\" \", header=None)\n",
    "    return df\n",
    "\n",
    "def merge_and_fillna(reference_df, target_df):\n",
    "    merged_df = pd.merge(reference_df, target_df, on=common_cols, how='left')\n",
    "    merged_df = merged_df.fillna(0)\n",
    "    return merged_df\n",
    "\n",
    "def clean_data(gain_range, loss_range, gain_indifference, loss_indifference):\n",
    "    ind_xyz = set(zip(gain_indifference[0].tolist(), gain_indifference[1].tolist(), gain_indifference[2].tolist()))\n",
    "    rng_xyz = set(zip(gain_range[0].tolist(), gain_range[1].tolist(), gain_range[2].tolist()))\n",
    "    xyz = ind_xyz | rng_xyz\n",
    "    all_coords = pd.DataFrame(list(xyz), columns=common_cols)\n",
    "    \n",
    "    new_gain_range = merge_and_fillna(all_coords, gain_range)\n",
    "    new_loss_range = merge_and_fillna(all_coords, loss_range)\n",
    "    new_gain_indifference = merge_and_fillna(all_coords, gain_indifference)\n",
    "    new_loss_indifference = merge_and_fillna(all_coords, loss_indifference)\n",
    "    return new_gain_range, new_loss_range, new_gain_indifference, new_loss_indifference\n",
    "\n",
    "def reset_data_frame(df):\n",
    "    df = df.transpose() # row = subject\n",
    "    df = df.drop(common_cols, axis='index') # drop rows with x,y,z\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_all_data():\n",
    "    gain_range = load_data(f\"{BASE_DIR}/gain_range_vmpfc.csv\")\n",
    "    loss_range = load_data(f\"{BASE_DIR}/loss_range_vmpfc.csv\")\n",
    "    gain_indifference = load_data(f\"{BASE_DIR}/gain_ind_vmpfc.csv\")\n",
    "    loss_indifference = load_data(f\"{BASE_DIR}/loss_ind_vmpfc.csv\")\n",
    "    \n",
    "    gain_range, loss_range, gain_indifference, loss_indifference = clean_data(gain_range, loss_range, gain_indifference, loss_indifference)\n",
    "    for d in [gain_range, loss_range, gain_indifference, loss_indifference]:\n",
    "        reset_data_frame(d)\n",
    "\n",
    "    gain_range[\"gain_or_loss\"] = 1\n",
    "    loss_range[\"gain_or_loss\"] = 0\n",
    "    gain_indifference[\"gain_or_loss\"] = 1\n",
    "    loss_indifference[\"gain_or_loss\"] = 0\n",
    "    \n",
    "    df = pd.concat([gain_range, loss_range, gain_indifference, loss_indifference]).reset_index(drop=True)\n",
    "    X = df.drop(\"gain_or_loss\", axis='columns').fillna(0).to_numpy()\n",
    "    y = df[\"gain_or_loss\"].to_numpy()\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.100000e+01,  8.200000e+01,  2.800000e+01,  5.286700e-01,\n",
       "       -6.887000e-01,  8.765780e-01,  4.309100e-01, -5.748650e-01,\n",
       "       -4.175370e-01,  5.740410e-01, -4.542860e-01,  4.550730e-01,\n",
       "        1.465250e-01, -5.445900e-02, -1.782050e-01, -5.623060e-01,\n",
       "       -8.397970e-01,  2.997080e-01,  3.142230e-01,  4.403300e-02,\n",
       "       -9.304300e-02,  1.362660e-01,  9.473000e-03,  2.489510e-01,\n",
       "       -4.098000e-01, -5.182590e-01, -6.476260e-01, -3.244400e-01,\n",
       "        6.271720e-01, -5.325970e-01, -8.117370e-01, -2.345210e-01,\n",
       "       -2.776790e-01,  5.519120e-01, -3.958970e-01, -2.549020e-01,\n",
       "       -5.483600e-01,  1.361590e-01,  4.145630e-01, -2.167000e-03,\n",
       "        3.812090e-01, -7.588290e-01, -5.588510e-01,  9.834300e-02,\n",
       "        1.024916e+00, -9.912600e-02, -6.494320e-01,  6.697200e-02,\n",
       "       -1.081290e-01,  2.864800e-01,  2.474340e-01,  8.025980e-01,\n",
       "        0.000000e+00,  0.000000e+00,  0.000000e+00])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15092, 55)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def crossval(estimator, X=X, y=y, k=10, scoring=None):\n",
    "    print(f\"Performing {k}-fold crossvalidation of {estimator}\")\n",
    "    cv_score = cross_val_score(estimator, X, y, cv=k, scoring=scoring)\n",
    "    print(f\"Scores: {cv_score}\")\n",
    "    print(f\"Average: {np.mean(cv_score)}. Stddev: {np.std(cv_score)}\")\n",
    "    return cv_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10-fold crossvalidation of SVC(kernel='linear', random_state=42)\n",
      "Scores: [0.78013245 0.77019868 0.77070908 0.78528827 0.77733598 0.81643472\n",
      " 0.82239894 0.79787939 0.81444665 0.83631544]\n",
      "Average: 0.7971139608266515. Stddev: 0.022564183155926915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.78013245, 0.77019868, 0.77070908, 0.78528827, 0.77733598,\n",
       "       0.81643472, 0.82239894, 0.79787939, 0.81444665, 0.83631544])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval(SVC(kernel='linear', C=1.0, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10-fold crossvalidation of SVC(C=0.001, kernel='linear', random_state=42)\n",
      "Scores: [0.77218543 0.77417219 0.77402253 0.78793903 0.77402253 0.82637508\n",
      " 0.81577203 0.80251822 0.81974818 0.83432737]\n",
      "Average: 0.7981082599326778. Stddev: 0.02327910321581979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.77218543, 0.77417219, 0.77402253, 0.78793903, 0.77402253,\n",
       "       0.82637508, 0.81577203, 0.80251822, 0.81974818, 0.83432737])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval(SVC(kernel='linear', C=0.001, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10-fold crossvalidation of SVC(C=100, kernel='linear', random_state=42)\n",
      "Scores: [0.78476821 0.77218543 0.77335984 0.78727634 0.77998675 0.81908549\n",
      " 0.82107356 0.7972167  0.81047051 0.83167661]\n",
      "Average: 0.7977099434299282. Stddev: 0.020382518001826614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.78476821, 0.77218543, 0.77335984, 0.78727634, 0.77998675,\n",
       "       0.81908549, 0.82107356, 0.7972167 , 0.81047051, 0.83167661])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval(SVC(kernel='linear', C=100, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10-fold crossvalidation of SVC(random_state=42)\n",
      "Scores: [0.75960265 0.75827815 0.76275679 0.77799867 0.76474486 0.82372432\n",
      " 0.82372432 0.80980782 0.82173625 0.83830351]\n",
      "Average: 0.7940677348711265. Stddev: 0.030489808980850016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.75960265, 0.75827815, 0.76275679, 0.77799867, 0.76474486,\n",
       "       0.82372432, 0.82372432, 0.80980782, 0.82173625, 0.83830351])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval(SVC(kernel='rbf', C=1.0, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10-fold crossvalidation of SVC(C=0.001, random_state=42)\n",
      "Scores: [0.7384106  0.7192053  0.49966865 0.49966865 0.49966865 0.49966865\n",
      " 0.49966865 0.49966865 0.49966865 0.49966865]\n",
      "Average: 0.5454965131945634. Stddev: 0.0917562674500282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.7384106 , 0.7192053 , 0.49966865, 0.49966865, 0.49966865,\n",
       "       0.49966865, 0.49966865, 0.49966865, 0.49966865, 0.49966865])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval(SVC(kernel='rbf', C=0.001, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10-fold crossvalidation of SVC(C=100, random_state=42)\n",
      "Scores: [0.78940397 0.77748344 0.78197482 0.78926441 0.78263751 0.82173625\n",
      " 0.82703777 0.80516899 0.81643472 0.83830351]\n",
      "Average: 0.802944540263935. Stddev: 0.020595308717217174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.78940397, 0.77748344, 0.78197482, 0.78926441, 0.78263751,\n",
       "       0.82173625, 0.82703777, 0.80516899, 0.81643472, 0.83830351])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval(SVC(kernel='rbf', C=100, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10-fold crossvalidation of RandomForestClassifier(max_depth=3, random_state=42)\n",
      "Scores: [0.70993377 0.69072848 0.70311465 0.71040424 0.68853545 0.78860172\n",
      " 0.77932406 0.77269715 0.77203446 0.78131213]\n",
      "Average: 0.7396686108514475. Stddev: 0.03990753247111766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.70993377, 0.69072848, 0.70311465, 0.71040424, 0.68853545,\n",
       "       0.78860172, 0.77932406, 0.77269715, 0.77203446, 0.78131213])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "crossval(RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10-fold crossvalidation of RandomForestClassifier(max_depth=4, n_estimators=200, random_state=42)\n",
      "Scores: [0.72781457 0.7013245  0.71371769 0.71901922 0.69648774 0.80185553\n",
      " 0.79191518 0.78528827 0.78396289 0.79456594]\n",
      "Average: 0.7515951531429526. Stddev: 0.04099581647568119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.72781457, 0.7013245 , 0.71371769, 0.71901922, 0.69648774,\n",
       "       0.80185553, 0.79191518, 0.78528827, 0.78396289, 0.79456594])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval(RandomForestClassifier(n_estimators=200, max_depth=4, random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10-fold crossvalidation of MLPClassifier(alpha=1e-05, hidden_layer_sizes=(50, 20), random_state=42,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/piotr/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/piotr/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/piotr/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/piotr/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/piotr/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/piotr/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/piotr/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/piotr/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.78211921 0.77086093 0.77269715 0.78396289 0.77667329 0.8250497\n",
      " 0.82637508 0.81047051 0.81047051 0.83366468]\n",
      "Average: 0.7992343949547748. Stddev: 0.02320651402238716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.78211921, 0.77086093, 0.77269715, 0.78396289, 0.77667329,\n",
       "       0.8250497 , 0.82637508, 0.81047051, 0.81047051, 0.83366468])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "crossval(MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 20), random_state=42, verbose=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
