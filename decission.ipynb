{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_TYPES = [\"indifference\", \"range\"]\n",
    "BASE_DIR = \"narpsdata/agh\"\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename, delimiter=\" \", header=None)\n",
    "    df = df.transpose() # row = subject\n",
    "    df = df.drop([0, 1, 2], axis='index') # drop rows with x,y,z\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def train_test_split(data, test_size=0.2):\n",
    "    msk = np.random.rand(len(data)) < (1 - test_size)\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "\n",
    "    return train.drop(\"label\", axis='columns').to_numpy(), train[\"label\"].to_numpy(), test.drop(\"label\", axis='columns').to_numpy(), test[\"label\"].to_numpy()\n",
    "\n",
    "def load_task_data(task, test_size=0.2):\n",
    "    if task not in TASK_TYPES:\n",
    "        raise Exception(f\"Available tasks: {TASK_TYPES}\")\n",
    "\n",
    "    gain = load_csv(f\"{BASE_DIR}/gain_{task}.csv\")\n",
    "    gain[\"label\"] = 1\n",
    "    loss = load_csv(f\"{BASE_DIR}/loss_{task}.csv\")\n",
    "    loss[\"label\"] = 0\n",
    "    df = pd.concat([gain, loss])\n",
    "    return train_test_split(df.reset_index(drop=True), test_size=test_size)\n",
    "X_train, y_train, X_test, y_test = load_task_data(\"range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_task_data(\"range\")\n",
    "clf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "BASE_DIR = \"narpsdata/agh\"\n",
    "common_cols = [0, 1, 2]\n",
    "\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename, delimiter=\" \", header=None)\n",
    "    return df\n",
    "\n",
    "def merge_and_fillna(reference_df, target_df):\n",
    "    merged_df = pd.merge(reference_df, target_df, on=common_cols, how='left')\n",
    "    merged_df = merged_df.fillna(0)\n",
    "    return merged_df\n",
    "\n",
    "def clean_data(gain_range, loss_range, gain_indifference, loss_indifference):\n",
    "    ranges = {}\n",
    "    for col in common_cols:\n",
    "        all_values = pd.concat([gain_range[col], loss_range[col], gain_indifference[col], loss_indifference[col]])\n",
    "        ranges[col] = (all_values.min(), all_values.max())\n",
    "    all_coords = pd.DataFrame([(i, j, k) for i in range(int(ranges[0][0]), int(ranges[0][1]) + 1)\n",
    "                                            for j in range(int(ranges[1][0]), int(ranges[1][1]) + 1)\n",
    "                                            for k in range(int(ranges[2][0]), int(ranges[2][1]) + 1)],\n",
    "                                            columns=common_cols)\n",
    "    new_gain_range = merge_and_fillna(all_coords, gain_range)\n",
    "    new_loss_range = merge_and_fillna(all_coords, loss_range)\n",
    "    new_gain_indifference = merge_and_fillna(all_coords, gain_indifference)\n",
    "    new_loss_indifference = merge_and_fillna(all_coords, loss_indifference)\n",
    "    return new_gain_range, new_loss_range, new_gain_indifference, new_loss_indifference\n",
    "\n",
    "def reset_data_frame(df):\n",
    "    df = df.transpose() # row = subject\n",
    "    df = df.drop(common_cols, axis='index') # drop rows with x,y,z\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def train_test_split(data, test_size=0.2):\n",
    "    msk = np.random.rand(len(data)) < (1 - test_size)\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "\n",
    "    return train.drop(\"gain_or_loss\", axis='columns').to_numpy(), train[\"gain_or_loss\"].to_numpy(), test.drop(\"gain_or_loss\", axis='columns').to_numpy(), test[\"gain_or_loss\"].to_numpy()\n",
    "\n",
    "def load_task_data(test_size=0.2):\n",
    "    gain_range = load_data(f\"{BASE_DIR}/gain_range.csv\")\n",
    "    loss_range = load_data(f\"{BASE_DIR}/loss_range.csv\")\n",
    "    gain_indifference = load_data(f\"{BASE_DIR}/gain_indifference.csv\")\n",
    "    loss_indifference = load_data(f\"{BASE_DIR}/loss_indifference.csv\")\n",
    "    \n",
    "    gain_range, loss_range, gain_indifference, loss_indifference = clean_data(gain_range, loss_range, gain_indifference, loss_indifference)\n",
    "    gain_range = reset_data_frame(gain_range)\n",
    "    loss_range = reset_data_frame(loss_range)\n",
    "    gain_indifference = reset_data_frame(gain_indifference)\n",
    "    loss_indifference = reset_data_frame(loss_indifference)\n",
    "\n",
    "    gain_range[\"gain_or_loss\"] = 1\n",
    "    loss_range[\"gain_or_loss\"] = 0\n",
    "    gain_indifference[\"gain_or_loss\"] = 1\n",
    "    loss_indifference[\"gain_or_loss\"] = 0\n",
    "#     gain_range[\"range_or_indifference\"] = 1\n",
    "#     loss_range[\"range_or_indifference\"] = 1\n",
    "#     gain_indifference[\"range_or_indifference\"] = 0\n",
    "#     loss_indifference[\"range_or_indifference\"] = 0\n",
    "    \n",
    "    df = pd.concat([gain_range, loss_range, gain_indifference, loss_indifference])\n",
    "    split_data =  train_test_split(df.reset_index(drop=True), test_size=test_size)\n",
    "    return split_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9183673469387755\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_task_data(0.2)\n",
    "clf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
