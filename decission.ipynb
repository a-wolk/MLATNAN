{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_TYPES = [\"indifference\", \"range\"]\n",
    "BASE_DIR = \"narpsdata/agh\"\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename, delimiter=\" \", header=None)\n",
    "    df = df.transpose() # row = subject\n",
    "    df = df.drop([0, 1, 2], axis='index') # drop rows with x,y,z\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def train_test_split(data, test_size=0.2):\n",
    "    msk = np.random.rand(len(data)) < (1 - test_size)\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "\n",
    "    return train.drop(\"label\", axis='columns').to_numpy(), train[\"label\"].to_numpy(), test.drop(\"label\", axis='columns').to_numpy(), test[\"label\"].to_numpy()\n",
    "\n",
    "def load_task_data(task, test_size=0.2):\n",
    "    if task not in TASK_TYPES:\n",
    "        raise Exception(f\"Available tasks: {TASK_TYPES}\")\n",
    "\n",
    "    gain = load_csv(f\"{BASE_DIR}/gain_{task}.csv\")\n",
    "    gain[\"label\"] = 1\n",
    "    loss = load_csv(f\"{BASE_DIR}/loss_{task}.csv\")\n",
    "    loss[\"label\"] = 0\n",
    "    df = pd.concat([gain, loss])\n",
    "    return train_test_split(df.reset_index(drop=True), test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "BASE_DIR = \"narpsdata/agh\"\n",
    "common_cols = [0, 1, 2]\n",
    "\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename, delimiter=\" \", header=None)\n",
    "    return df\n",
    "\n",
    "def merge_and_fillna(reference_df, target_df):\n",
    "    merged_df = pd.merge(reference_df, target_df, on=common_cols, how='left')\n",
    "    merged_df = merged_df.fillna(0)\n",
    "    return merged_df\n",
    "\n",
    "def clean_data(gain_range, loss_range, gain_indifference, loss_indifference):\n",
    "    ind_xyz = set(zip(gain_indifference[0].tolist(), gain_indifference[1].tolist(), gain_indifference[2].tolist()))\n",
    "    rng_xyz = set(zip(gain_range[0].tolist(), gain_range[1].tolist(), gain_range[2].tolist()))\n",
    "    xyz = ind_xyz | rng_xyz\n",
    "    all_coords = pd.DataFrame(list(xyz), columns=common_cols)\n",
    "    \n",
    "    new_gain_range = merge_and_fillna(all_coords, gain_range)\n",
    "    new_loss_range = merge_and_fillna(all_coords, loss_range)\n",
    "    new_gain_indifference = merge_and_fillna(all_coords, gain_indifference)\n",
    "    new_loss_indifference = merge_and_fillna(all_coords, loss_indifference)\n",
    "    return new_gain_range, new_loss_range, new_gain_indifference, new_loss_indifference\n",
    "\n",
    "def reset_data_frame(df):\n",
    "    df = df.transpose() # row = subject\n",
    "    df = df.drop(common_cols, axis='index') # drop rows with x,y,z\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def train_test_split_merged(data, test_size=0.2):\n",
    "    msk = np.random.rand(len(data)) < (1 - test_size)\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "\n",
    "    return train.drop(\"gain_or_loss\", axis='columns').to_numpy(), train[\"gain_or_loss\"].to_numpy(), test.drop(\"gain_or_loss\", axis='columns').to_numpy(), test[\"gain_or_loss\"].to_numpy()\n",
    "\n",
    "def load_task_data_merged(test_size=0.2):\n",
    "    gain_range = load_data(f\"{BASE_DIR}/gain_range.csv\")\n",
    "    loss_range = load_data(f\"{BASE_DIR}/loss_range.csv\")\n",
    "    gain_indifference = load_data(f\"{BASE_DIR}/gain_indifference.csv\")\n",
    "    loss_indifference = load_data(f\"{BASE_DIR}/loss_indifference.csv\")\n",
    "    \n",
    "    gain_range, loss_range, gain_indifference, loss_indifference = clean_data(gain_range, loss_range, gain_indifference, loss_indifference)\n",
    "    gain_range = reset_data_frame(gain_range)\n",
    "    loss_range = reset_data_frame(loss_range)\n",
    "    gain_indifference = reset_data_frame(gain_indifference)\n",
    "    loss_indifference = reset_data_frame(loss_indifference)\n",
    "\n",
    "    gain_range[\"gain_or_loss\"] = 1\n",
    "    loss_range[\"gain_or_loss\"] = 0\n",
    "    gain_indifference[\"gain_or_loss\"] = 1\n",
    "    loss_indifference[\"gain_or_loss\"] = 0\n",
    "    \n",
    "    df = pd.concat([gain_range, loss_range, gain_indifference, loss_indifference])\n",
    "    split_data =  train_test_split_merged(df.reset_index(drop=True), test_size=test_size)\n",
    "    return split_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_task_data_merged(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 465551)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Number of support vectors:  151\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Number of support vectors: \", len(clf.support_vectors_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Number of support vectors:  151\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=0.001, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Number of support vectors: \", len(clf.support_vectors_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Number of support vectors:  151\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Number of support vectors: \", len(clf.support_vectors_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Number of support vectors:  152\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Number of support vectors: \", len(clf.support_vectors_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46\n",
      "Number of support vectors:  148\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=0.001, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Number of support vectors: \", len(clf.support_vectors_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n",
      "Number of support vectors:  152\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Number of support vectors: \", len(clf.support_vectors_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.36170229e-02, 1.86061246e-02, 1.39463851e-02, 1.04874338e-02,\n",
       "       1.00899073e-02, 9.90239129e-03, 9.69366337e-03, 9.42622259e-03,\n",
       "       9.25913786e-03, 9.18191340e-03, 9.08612320e-03, 8.85415569e-03,\n",
       "       8.76130067e-03, 8.50121470e-03, 8.48193135e-03, 8.27263244e-03,\n",
       "       8.24196429e-03, 8.16955807e-03, 8.05972293e-03, 7.93511924e-03,\n",
       "       7.91195464e-03, 7.86153315e-03, 7.82523918e-03, 7.74311068e-03,\n",
       "       7.67076625e-03, 7.58921506e-03, 7.53722855e-03, 7.48465512e-03,\n",
       "       7.42629438e-03, 7.40149342e-03, 7.33146440e-03, 7.24550814e-03,\n",
       "       7.23450410e-03, 7.22403273e-03, 7.13217471e-03, 7.07072830e-03,\n",
       "       7.04683991e-03, 7.02166597e-03, 6.99615871e-03, 6.95404475e-03,\n",
       "       6.91853627e-03, 6.88451964e-03, 6.85530184e-03, 6.84609900e-03,\n",
       "       6.78130707e-03, 6.73602934e-03, 6.68064122e-03, 6.66611690e-03,\n",
       "       6.61543144e-03, 6.57749764e-03, 6.57647221e-03, 6.53896752e-03,\n",
       "       6.51586090e-03, 6.49695540e-03, 6.45387533e-03, 6.42847835e-03,\n",
       "       6.41193179e-03, 6.35538299e-03, 6.32057433e-03, 6.29528136e-03,\n",
       "       6.26533381e-03, 6.25156001e-03, 6.23651915e-03, 6.21712112e-03,\n",
       "       6.18263835e-03, 6.16279377e-03, 6.14437757e-03, 6.14006392e-03,\n",
       "       6.10628955e-03, 6.08983444e-03, 6.07384463e-03, 6.06374203e-03,\n",
       "       6.04636023e-03, 6.02651055e-03, 6.01595843e-03, 5.97889638e-03,\n",
       "       5.96627117e-03, 5.94374000e-03, 5.93195504e-03, 5.92379056e-03,\n",
       "       5.90921805e-03, 5.88354385e-03, 5.87069934e-03, 5.84987727e-03,\n",
       "       5.83905691e-03, 5.82508687e-03, 5.81115244e-03, 5.78619711e-03,\n",
       "       5.76915116e-03, 5.75992578e-03, 5.73712493e-03, 5.72073446e-03,\n",
       "       5.71199286e-03, 5.68910325e-03, 5.67883677e-03, 5.66381302e-03,\n",
       "       5.63857197e-03, 5.62856493e-03, 5.60979161e-03, 5.59965949e-03,\n",
       "       5.58072636e-03, 5.55923847e-03, 5.54484775e-03, 5.54302622e-03,\n",
       "       5.52247498e-03, 5.50838768e-03, 5.48313148e-03, 5.47126029e-03,\n",
       "       5.45956348e-03, 5.44864857e-03, 5.43780609e-03, 5.42604013e-03,\n",
       "       5.39711940e-03, 5.39080256e-03, 5.37188086e-03, 5.36474850e-03,\n",
       "       5.34374803e-03, 5.32963674e-03, 5.32197019e-03, 5.31000792e-03,\n",
       "       5.29785697e-03, 5.29006000e-03, 5.26450082e-03, 5.24711272e-03,\n",
       "       5.22594627e-03, 5.19964121e-03, 5.19241573e-03, 5.17470492e-03,\n",
       "       5.15827121e-03, 5.13497572e-03, 5.13027292e-03, 5.11909329e-03,\n",
       "       5.09791629e-03, 5.08179733e-03, 5.07144167e-03, 5.04719169e-03,\n",
       "       5.04253332e-03, 5.03344416e-03, 5.02349356e-03, 4.98899758e-03,\n",
       "       4.98439284e-03, 4.96984472e-03, 4.94995608e-03, 4.93648907e-03,\n",
       "       4.92019501e-03, 4.88317887e-03, 4.86536101e-03, 4.80529001e-03,\n",
       "       4.71581129e-03, 4.68342747e-03, 4.66182017e-03, 1.70784439e-31])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arczipt/Desktop/MLATNAN/.venv/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py:128: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FastICA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FastICA</label><div class=\"sk-toggleable__content\"><pre>FastICA()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "FastICA()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "ica = FastICA()\n",
    "ica.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =     23278641     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.29167D-01    |proj g|=  7.19568D-02\n",
      "\n",
      "At iterate    1    f=  2.07987D-01    |proj g|=  1.92164D-01\n",
      "\n",
      "At iterate    2    f=  2.01430D-02    |proj g|=  1.03691D-01\n",
      "\n",
      "At iterate    3    f=  1.09389D-02    |proj g|=  5.33114D-02\n",
      "\n",
      "At iterate    4    f=  6.38001D-03    |proj g|=  3.23691D-02\n",
      "\n",
      "At iterate    5    f=  2.71995D-03    |proj g|=  1.50777D-02\n",
      "\n",
      "At iterate    6    f=  1.02483D-03    |proj g|=  5.91290D-03\n",
      "\n",
      "At iterate    7    f=  5.41048D-04    |proj g|=  3.18645D-03\n",
      "\n",
      "At iterate    8    f=  2.18303D-04    |proj g|=  1.29439D-03\n",
      "\n",
      "At iterate    9    f=  1.05503D-04    |proj g|=  6.35375D-04\n",
      "\n",
      "At iterate   10    f=  5.08626D-05    |proj g|=  3.02062D-04\n",
      "\n",
      "At iterate   11    f=  2.54628D-05    |proj g|=  1.40260D-04\n",
      "\n",
      "At iterate   12    f=  1.40264D-05    |proj g|=  6.68200D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     12     13      1     0     0   6.682D-05   1.403D-05\n",
      "  F =   1.4026400933428077E-005\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 20), random_state=42, verbose=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
